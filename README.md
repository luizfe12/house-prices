   Previs√£o de Pre√ßos de Im√≥veis
Este √© um projeto de Machine Learning para iniciantes cujo objetivo √© prever o pre√ßo de im√≥veis com base em suas caracter√≠sticas. O script implementa um pipeline completo, desde o carregamento e pr√©-processamento dos dados at√© o treinamento e avalia√ß√£o comparativa de dois modelos de regress√£o.

üìú Sobre o Projeto
O modelo utiliza um conjunto de dados de im√≥veis para aprender a rela√ß√£o entre features como √°rea, n√∫mero de quartos, localiza√ß√£o, etc., e seu pre√ßo de venda. Foram treinados e avaliados dois algoritmos distintos para comparar suas performances:

Regress√£o Linear: Um modelo linear simples e interpret√°vel.

Random Forest Regressor: Um modelo de conjunto (ensemble) mais complexo e poderoso, capaz de aprender rela√ß√µes n√£o-lineares.

A m√©trica de avalia√ß√£o utilizada foi o Erro M√©dio Absoluto (MAE), que nos informa, em m√©dia, o quanto as previs√µes do modelo erram em rela√ß√£o ao pre√ßo real.

‚ú® Funcionalidades
Carregamento de Dados: Carrega os dados a partir de um arquivo house-prices.csv.

Pr√©-processamento:

Label Encoding: Transforma features bin√°rias (como 'sim'/'n√£o') em 0 e 1.

One-Hot Encoding: Transforma features categ√≥ricas com m√∫ltiplos valores (como 'localiza√ß√£o') em colunas bin√°rias para evitar a cria√ß√£o de uma ordem artificial.

Feature Scaling: Padroniza as features num√©ricas usando StandardScaler para que todas tenham a mesma escala, otimizando o desempenho dos modelos.

Treinamento de Modelos: Treina e compara a performance de uma Regress√£o Linear e um Random Forest.

Avalia√ß√£o: Calcula o erro m√©dio absoluto e o erro percentual m√©dio para ambos os modelos, facilitando a interpreta√ß√£o e compara√ß√£o dos resultados.

üõ†Ô∏è Tecnologias Utilizadas
O projeto foi desenvolvido inteiramente em Python, utilizando as seguintes bibliotecas:

Python 3.x

Pandas: Para manipula√ß√£o e an√°lise de dados.

NumPy: Para opera√ß√µes num√©ricas eficientes.

Scikit-learn: Para o pr√©-processamento dos dados e a implementa√ß√£o dos modelos de Machine Learning.

üöÄ Como Executar o Projeto
Siga os passos abaixo para executar o projeto em sua m√°quina local.

Pr√©-requisitos
Python 3.8 ou superior

Git (para clonar o reposit√≥rio)

Passos de Instala√ß√£o
Clone o reposit√≥rio:

Bash

git clone https://github.com/SEU_USUARIO/NOME_DO_SEU_REPOSITORIO.git
cd NOME_DO_SEU_REPOSITORIO
Crie e ative um ambiente virtual (Recomendado):

Bash

# Cria o ambiente
python -m venv venv

# Ativa no Windows
.\venv\Scripts\activate

# Ativa no macOS/Linux
source venv/bin/activate
Crie o arquivo requirements.txt:
Crie um arquivo chamado requirements.txt na raiz do projeto e adicione o seguinte conte√∫do:

Plaintext

pandas
numpy
scikit-learn
Instale as depend√™ncias:

Bash

pip install -r requirements.txt
Executando o Script
Com o ambiente virtual ativado e as depend√™ncias instaladas, execute o script principal:

Bash

python nome_do_seu_script.py
üìä Exemplo de Sa√≠da
Ao executar o script, voc√™ ver√° a seguinte sa√≠da no terminal com a avalia√ß√£o de performance dos modelos:

========================================
      RESULTADOS FINAIS DE PERFORMANCE      
========================================
Pre√ßo m√©dio dos im√≥veis: R$ 130,427.34

--- Modelo: Regress√£o Linear ---
Erro M√©dio Absoluto: R$ 7,512.37
Erro Percentual M√©dio: 5.76%

--- Modelo: Random Forest Regressor ---
Erro M√©dio Absoluto: R$ 9,721.97
Erro Percentual M√©dio: 7.45%

========================================
üìà An√°lise dos Resultados
========================================
√â interessante notar que, para este conjunto de dados e com os par√¢metros padr√£o, o modelo de Regress√£o Linear (erro de 5.76%) superou o Random Forest (erro de 7.45%).

Isso √© um fen√¥meno comum em Machine Learning e sugere que a simplicidade do modelo linear foi mais robusta e generalizou melhor para os dados de teste. O modelo Random Forest, por ser mais complexo, pode ter sofrido um leve overfitting (quando o modelo "decora" os dados de treino em vez de aprender a tend√™ncia geral), o que √© comum em datasets com poucas amostras.

üîÆ Pr√≥ximos Passos e Melhorias
Este projeto serve como uma base s√≥lida. Algumas ideias para expandi-lo incluem:

[ ] Realizar a otimiza√ß√£o de hiperpar√¢metros do Random Forest (usando GridSearchCV ou RandomizedSearchCV) para tentar superar o resultado da Regress√£o Linear.

[ ] Implementar mais modelos de regress√£o (ex: XGBoost, LightGBM).

[ ] Criar novas features (engenharia de features) para melhorar a precis√£o.

[ ] Adicionar mais visualiza√ß√µes de dados, como gr√°ficos de distribui√ß√£o e matriz de correla√ß√£o.

[ ] Envolver o melhor modelo treinado em uma API simples usando Flask ou FastAPI.
